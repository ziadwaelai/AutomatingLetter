import os
import json
import logging
import re
from datetime import datetime
from typing import Optional, Dict, Any
from dataclasses import dataclass, field

from google_services import log 

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import Runnable
import random

# Assuming google_services.log exists. If not, this can be swapped with another logger.
# from google_services import log 

# --- Setup (Can be moved to a separate config.py) ---

# 1. Standardized Logging Setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2. Centralized Configuration
@dataclass
class LetterGeneratorConfig:
    """Configuration settings for the letter generator."""
    model_name: str = "gpt-4.1" 
    temperature: float = 0.1
    date_format: str = "%d %B %Y"
    
    # Default texts
    writing_instructions: str = "Please ensure the letter is formal, clear, and adheres to the standard Arabic letter format."
    reference_context: str = "Use a standard Arabic formal letter format if no style reference is provided."
    default_tone: str = "Ø±Ø³Ù…ÙŠ"
    
    # Logging Configuration
    log_spreadsheet: str = "AI Letter Generating"
    log_worksheet: str = "Logs"

# --- Utility Functions ---

def generate_letter_id() -> str:
    """Generate a random ID in the format AIZ-YYYYMMDD-XXXXX."""
    # Using a more robust method for random part to ensure 5 digits
    random_part = str(random.randint(0, 99999)).zfill(5)
    date_part = datetime.now().strftime("%Y%m%d")
    return f"AIZ-{date_part}-{random_part}"

# --- Pydantic Output Model ---

class LetterOutput(BaseModel):
    """Pydantic model for the final letter output, including the generated ID."""
    ID: str = Field(description="The unique identifier for the letter.")
    Title: str = Field(description="The title of the letter in Arabic.")
    Letter: str = Field(description="The full content of the letter in formal Arabic.")
    Date: str = Field(description="The date the letter was generated.")

# --- Core Logic ---

class ArabicLetterGenerator:
    """
    An optimized class to generate professional Arabic letters using an LLM.
    
    This class builds a reusable LangChain Expression Language (LCEL) chain 
    for efficient and robust letter generation.
    """
    
    def __init__(self, config: LetterGeneratorConfig = LetterGeneratorConfig()):
        """
        Initializes the generator with a configuration and sets up the LLM chain.
        """
        self.config = config
        self.api_key = self._load_api_key()
        self.parser = JsonOutputParser(pydantic_object=LetterOutput)
        
        # Build the chain once during initialization for efficiency
        self.chain = self._build_chain()

    def _load_api_key(self) -> str:
        """Loads OpenAI API key from environment variables."""
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise EnvironmentError("OPENAI_API_KEY is missing. Please set it in your environment.")
        return api_key

    def _get_prompt_template(self) -> PromptTemplate:
        """
        Creates and returns a robust prompt template for letter generation.
        This version strictly separates content generation from style guidance.
        """
        template = """
Ø£Ù†Øª ÙƒØ§ØªØ¨ Ø®Ø·Ø§Ø¨Ø§Øª Ù…Ø­ØªØ±Ù ÙˆÙ…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ø´Ø±ÙƒØ© `Ù†Øª Ø²ÙŠØ±Ùˆ`. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ÙƒØªØ§Ø¨Ø© Ø®Ø·Ø§Ø¨ Ø±Ø³Ù…ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ù…Ø¹ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø§Ù„ØµØ§Ø±Ù… Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø£Ø¯Ù†Ø§Ù‡.

# Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
1. **Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙƒØªØ§Ø¨ØªÙ‡):** {user_prompt}
2. **Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù‡ÙŠÙƒÙ„ ÙˆØ§Ù„Ø£Ø³Ù„ÙˆØ¨ (Ù„Ù„Ø§Ø³ØªØ±Ø´Ø§Ø¯ Ø¨Ø§Ù„Ø´ÙƒÙ„ ÙÙ‚Ø·):** {reference_context}
3. **Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„Ø®Ø·Ø§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯:** {additional_context}
4. **Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙØ±Ø³ÙÙ„:** {member_info}
5. **ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨Ø©:** {writing_instructions}
6. **Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø·Ø§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯:**
   - Ù…Ø¹Ø±Ù Ø§Ù„Ø®Ø·Ø§Ø¨: {letter_id}
   - ØªØ§Ø±ÙŠØ® Ø§Ù„ÙŠÙˆÙ…: {current_date}

# ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø© ÙŠØ¬Ø¨ Ø§ØªØ¨Ø§Ø¹Ù‡Ø§
1. âœ… **ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ³ØªÙ†Ø¯ Ø§Ù„Ø®Ø·Ø§Ø¨ ÙÙ‚Ø· Ø¥Ù„Ù‰ "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ".** Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø£Ùˆ ÙÙƒØ±Ø© Ù…Ù† Ø®Ø§Ø±Ø¬ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù….
2. âœ… **Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ ÙŠØ³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ù„ØªÙ‚Ù„ÙŠØ¯ Ø§Ù„Ø´ÙƒÙ„ ÙˆØ§Ù„ØªÙ†Ø³ÙŠÙ‚ (Ù…Ù‚Ø¯Ù…Ø©/ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙÙ‚Ø±Ø§Øª/Ø§Ù„Ø®Ø§ØªÙ…Ø©)**ØŒ ÙˆÙŠÙÙ…Ù†Ø¹ ØªÙ…Ø§Ù…Ù‹Ø§ Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø£ÙŠ Ø¬Ù…Ù„Ø©ØŒ Ø£Ùˆ Ø£Ø®Ø° Ø£Ø³Ù…Ø§Ø¡ Ø£Ùˆ Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ ØªÙˆØ§Ø±ÙŠØ® Ù…Ù†Ù‡.
3. â›” **Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ø¹Ø¨Ø§Ø±Ø§Øª ØªÙ‡Ù†Ø¦Ø© Ø£Ùˆ Ù…Ù†Ø§Ø³Ø¨Ø§Øª Ø£Ùˆ Ø£Ù„Ù‚Ø§Ø¨ Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ÙŠØ© (Ù…Ø«Ù„: "Ø³Ù„Ù…Ù‡ Ø§Ù„Ù„Ù‡"ØŒ "Ø­ÙØ¸Ù‡ Ø§Ù„Ù„Ù‡") Ø£Ùˆ Ø¯Ø¹Ø§Ø¡ Ø£Ùˆ Ø´ÙƒØ± Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø°ÙÙƒØ±Øª ØµØ±Ø§Ø­Ø© ÙÙŠ "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ".** Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØ°ÙƒØ± Ø¹ÙŠØ¯ Ø£Ùˆ Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙ„Ø§ ØªØ¨Ø¯Ø£ Ø§Ù„Ø®Ø·Ø§Ø¨ Ø¨Ø£ÙŠ ØªÙ‡Ù†Ø¦Ø©.
4. ğŸ§  **Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø§Ø¨ Ø¬Ø¯ÙŠØ¯ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø­ÙˆÙ„ "{user_prompt}" ÙÙ‚Ø·ØŒ ÙˆÙ„Ø§ ØªÙ‚Ù… Ø¨ØªÙ„Ø®ÙŠØµ Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ Ø£Ùˆ Ø§Ø³ØªØ¹Ø§Ø±Ø© Ø£ÙŠ Ù…Ù† Ø¹Ù†Ø§ØµØ±Ù‡ Ø§Ù„Ù†ØµÙŠØ©.**
5. ğŸ“ **Ø§Ù„Ø®Ø·Ø§Ø¨ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ÙØµÙ„Ù‹Ø§ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠÙ‹Ø§ØŒ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ØŒ Ù…Ø¹ Ø§Ù„ØªØ²Ø§Ù… ÙƒØ§Ù…Ù„ Ø¨Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©ØŒ Ø¹Ø±Ø¶ Ø§Ù„ØºØ±Ø¶ ÙˆØ§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©ØŒ Ø´Ø±Ø­ ÙˆØ§Ø¶Ø­ Ù„Ø£ÙŠ ÙØ¹Ø§Ù„ÙŠØ© Ø£Ùˆ Ø·Ù„Ø¨ØŒ ÙˆØ¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø®Ø·Ø§Ø¨ Ø¨ØµÙŠØºØ© Ø±Ø³Ù…ÙŠØ© Ù…Ø­ØªØ±Ù…Ø© (Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ø·ÙŠØ§Øª).**
6. â›” **Ù„Ø§ ØªØ¯Ø®Ù„ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙˆØ§ØµÙ„ (Ø£Ø³Ù…Ø§Ø¡ØŒ Ø£Ø±Ù‚Ø§Ù…ØŒ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØŒ ØªÙˆÙ‚ÙŠØ¹Ø§Øª) Ø¥Ù„Ø§ Ù…Ù† "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙØ±Ø³ÙÙ„"ØŒ ÙˆÙ„Ø§ ØªÙØªØ±Ø¶ Ø£Ùˆ ØªØ³ØªÙ†ØªØ¬ Ø£Ùˆ ØªÙ†Ù‚Ù„ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ.**
7. âœ… **Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø®Ø·Ø§Ø¨ Ø¨Ù‡Ø°Ø§ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¥Ù„Ø²Ø§Ù…ÙŠÙ‹Ø§:** "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…"ØŒ Ø«Ù… Ø§Ø³Ù… Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø¨Ø© (Ø­Ø³Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø·Ø§Ø¨ Ø£Ùˆ Ø§Ù„Ø³ÙŠØ§Ù‚)ØŒ Ø«Ù… Ø§Ù„ØªØ­ÙŠØ© Ø§Ù„Ø±Ø³Ù…ÙŠØ© ("Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡")ØŒ Ø«Ù… Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø§Ø¨.
8. âœ… **ÙÙŠ Ø¥Ø®Ø±Ø§Ø¬ JSONØŒ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø­Ù‚Ù„ "Title" Ø¹Ù†ÙˆØ§Ù†Ù‹Ø§ Ù…Ø®ØªØµØ±Ù‹Ø§ Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ Ù„Ù„Ø®Ø·Ø§Ø¨ Ù…Ø³ØªÙ…Ø¯Ù‹Ø§ ÙÙ‚Ø· Ù…Ù† "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ"ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø¹Ø¨Ø§Ø±Ø§Øª ØªØ±Ø­ÙŠØ¨ Ø£Ùˆ ØªÙ‡Ù†Ø¦Ø©.**
9. âœ… **Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ØµØ§Ù„Ø­ 100% ÙˆØ¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø®Ø§Ø±Ø¬ÙŠ Ø£Ùˆ ØªØ¹Ù„ÙŠÙ‚ØŒ ÙˆÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¯Ù‚Ø©.**
10. â›” **Ù„Ø§ ØªÙƒØ±Ø± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ø®Ø·Ø§Ø¨ Ø¨Ø£ÙƒØ«Ø± Ù…Ù† ØµÙŠØ§ØºØ©.**
11. âœ… **ÙÙŠ Ø­Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ø£ÙŠ ØªØ¹Ø§Ø±Ø¶ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§ØªØŒ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.**
12. â›” **Ù„Ø§ ØªØ¶Ù Ø£Ùˆ ØªØ³ØªÙ†ØªØ¬ Ø£ÙŠ ÙÙ‚Ø±Ø§Øª Ø£Ùˆ Ø¬Ù…Ù„ ØºÙŠØ± Ù…Ù†ØµÙˆØµ Ø¹Ù„ÙŠÙ‡Ø§ Ø¨ÙˆØ¶ÙˆØ­ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø£Ùˆ "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ".**

{format_instructions}
"""





        return PromptTemplate.from_template(
            template,
            partial_variables={"format_instructions": self.parser.get_format_instructions()}
        )
    def _build_chain(self) -> Runnable:
        """Constructs the full LCEL chain: prompt -> llm -> parser."""
        prompt = self._get_prompt_template()
        llm = ChatOpenAI(
            model_name=self.config.model_name,
            temperature=self.config.temperature,
            openai_api_key=self.api_key
        )
        # print the prompt template for debugging with data 
        return prompt | llm | self.parser

    def _log_generation(self, request_data: Dict[str, Any], response_data: Dict[str, Any]) -> None:
        """Logs request and response details."""
        try:
            log_entry = {
                "Timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "ID": response_data.get("ID", ""),
                "Request": json.dumps(request_data, ensure_ascii=False),
                "Response": json.dumps(response_data, ensure_ascii=False),
            }
            logger.info(f"Logging generation for ID: {log_entry['ID']}")
            log(
                spreadsheet_name=self.config.log_spreadsheet,
                worksheet_name=self.config.log_worksheet,
                entries=[log_entry]
            )
        except Exception as e:
            logger.error(f"Failed to log letter generation: {e}")

 # --- THIS IS THE UPDATED METHOD ---
    def generate_letter(
        self,
        user_prompt: str,
        recipient: Optional[str] = None,
        member_info: str = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
        is_first_contact: bool = False,
        reference_letter: Optional[str] = None,
        category: str = "General", # Added for better logging
        writing_instructions: Optional[str] = None,
        
    ) -> LetterOutput:
        """
        Generates a professional Arabic letter by invoking the pre-built chain.

        Args:
            user_prompt: Main instruction describing what the letter should say.
            title: Title of the letter (e.g., "Ø·Ù„Ø¨ Ø´Ù‡Ø§Ø¯Ø© Ø®Ø¨Ø±Ø©").
            recipient: Name of the recipient.
            member_info: Information about the sender.
            is_first_contact: Whether this is the first communication with the recipient.
            reference_letter: A model letter to guide style and structure.
            tone: The tone of the letter (e.g., "Ø±Ø³Ù…ÙŠ", "ÙˆØ¯ÙŠ", "Ø­Ø§Ø²Ù…").
            category: Category of the letter for logging purposes.

        Returns:
            A LetterOutput object containing the generated letter details.
            
        Raises:
            ValueError: If the user_prompt is empty.
            RuntimeError: If the LLM fails to generate a valid response.
        """
        if not user_prompt:
            raise ValueError("A prompt is required to generate the letter.")

        letter_id = generate_letter_id()
        current_date = datetime.now().strftime(self.config.date_format)

        context_parts = []
        if recipient: context_parts.append(f"Recipient: {recipient}")
        if is_first_contact: context_parts.append("Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø£ÙˆÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙ„Ù….")
        
        input_data = {
            "user_prompt": user_prompt,
            "reference_context": reference_letter or self.config.reference_context,
            "additional_context": "\n".join(context_parts) or "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©.",
            "writing_instructions": writing_instructions or self.config.writing_instructions,
            "member_info": member_info,
            "letter_id": letter_id,
            "current_date": current_date
        }

        
        try:
            # The chain returns a dictionary that conforms to the schema
            print("Invoking the chain with input data...")
            parsed_dict = self.chain.invoke(input_data)
            
            # **FIX:** Explicitly create the Pydantic object from the dictionary.
            # This validates the data and gives us the object we expect.
            letter_output = LetterOutput(**parsed_dict)

            # Now, call .model_dump() on the Pydantic object for logging
            self._log_generation(
                request_data={**input_data, "category": category},
                response_data=letter_output.model_dump()
            )
            
            # Return the validated Pydantic object
            return letter_output

        except Exception as e:
            logger.error(f"Letter generation failed for prompt '{user_prompt[:50]}...': {e}")
            raise RuntimeError(f"Failed to generate or parse the letter. Original error: {e}")